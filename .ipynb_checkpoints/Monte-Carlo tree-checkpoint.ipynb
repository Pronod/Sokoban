{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_sokoban.envs\n",
    "from gym_sokoban.envs import SokobanEnv\n",
    "from gym.spaces import Discrete, Box\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "from Networks import ValueNetwork, ClassificationNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d472ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state_snapshot, parent = None, parent_action = 0, actions_num = 4):\n",
    "        self.state_snapshot = state_snapshot\n",
    "        self.childs = [None] * actions_num\n",
    "        self.rewards = np.array([0.0] * actions_num)\n",
    "        self.estimated_values = np.array([0.0] * actions_num)\n",
    "        self.value = 0.0\n",
    "        self.actions_num = actions_num\n",
    "        self.parent = parent\n",
    "        self.parent_action = parent_action\n",
    "        \n",
    "    def get_by_action(self, action):\n",
    "        return self.childs[action]\n",
    "    \n",
    "    def set_node_for_action(self, action, other_node):\n",
    "        self.childs[action] = other_node\n",
    "        \n",
    "    def set_reward_for_action(self, action, reward):\n",
    "        self.rewards[action] = reward\n",
    "        \n",
    "    def update_value_for_action(self, action, value):\n",
    "        self.value = (self.rewards + self.estimated_values).max()\n",
    "        \n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "    \n",
    "    def set_value(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def get_parent(self):\n",
    "        return self.parent, self.parent_action\n",
    "    \n",
    "    def get_snapshot(self):\n",
    "        return self.state_snapshot\n",
    "    \n",
    "    def get_best_action(self):\n",
    "        return self.argmax(self.estimated_values + self.rewards) + 1\n",
    "    \n",
    "    def argmax(self, values):\n",
    "        tie = []\n",
    "        for idx, val in enumerate(values):\n",
    "            if len(tie) == 0 or val > values[tie[0]]:\n",
    "                tie = [idx]\n",
    "            elif val == values[tie[0]]:\n",
    "                tie.append(idx)\n",
    "        return np.random.choice(tie)\n",
    "    \n",
    "    def select(self):\n",
    "        euristics = []\n",
    "        for i in range(self.actions_num):\n",
    "            val = self.rewards[i] + self.estimated_values[i]\n",
    "            euristics.append(val)\n",
    "        action = self.argmax(euristics)\n",
    "        if self.childs[action] is None:\n",
    "            return self, action\n",
    "        else:\n",
    "            return self.childs[action].select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3182c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, env, network, rollout_times = 20):\n",
    "        self.env = env\n",
    "        self.network = network\n",
    "        self.rollout_times = rollout_times\n",
    "        self.states_to_train = np.array([])\n",
    "        self.targets = np.array([])\n",
    "        \n",
    "    def iterate(self, init_snapshot, net_type, train):\n",
    "        root = Node(init_snapshot)\n",
    "        for _ in range(self.rollout_times):\n",
    "            parent_node, action = root.select()\n",
    "            \n",
    "            snapshot = parent_node.get_snapshot()\n",
    "            env.set_state(snapshot)\n",
    "            state, reward, done, _ = env.step(action + 1)\n",
    "            if net_type == 'value':\n",
    "                estimated_V = self.network.get_V(state)[0][0]\n",
    "            else:\n",
    "                estimated_V_prob = self.network.get_V(state)[0][0]\n",
    "                estimated_V = 10.0 if estimated_V_prob > 0.9 else (-5.0 if estimated_V_prob < 0.1 else 0.0)\n",
    "            \n",
    "            snapshot = env.get_state_snapshot()\n",
    "            child = Node(snapshot, parent_node, action)\n",
    "            child.set_value(estimated_V)\n",
    "            \n",
    "            parent_node.set_reward_for_action(action, reward)\n",
    "            parent_node.set_node_for_action(action, child)\n",
    "            \n",
    "            node = child\n",
    "            while not (node is None):\n",
    "                value = node.get_value()\n",
    "                parent, parent_action = node.get_parent()\n",
    "                if not (parent is None):\n",
    "                    parent.update_value_for_action(parent_action, value)\n",
    "                node = parent\n",
    "                \n",
    "        \n",
    "        return root.get_best_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "up = 1\n",
    "down = 2\n",
    "left = 3\n",
    "right = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(env, network, net_type, rollouts, init_states, train, iteration_number_max):\n",
    "    mcts = MCTS(env, network, rollouts)\n",
    "    \n",
    "    solved = []\n",
    "    done = False\n",
    "\n",
    "    for i, init_snapshot in enumerate(init_states):\n",
    "        print(\"play\", i)\n",
    "        iteration_number = 0\n",
    "        done = False\n",
    "        \n",
    "        states_to_train = []\n",
    "\n",
    "        while not done:\n",
    "            iteration_number += 1\n",
    "            action = mcts.iterate(init_snapshot, net_type, train=train)\n",
    "            env.set_state(init_snapshot)\n",
    "            if train:\n",
    "                states_to_train.append(env.render('rgb_array'))\n",
    "            \n",
    "            state, reward, done, _ = env.step(action)\n",
    "            init_snapshot = env.get_state_snapshot()\n",
    "            if done or iteration_number == iteration_number_max:\n",
    "                if train:\n",
    "                    targets = [0.0 if iteration_number == iteration_number_max else 10.0]\n",
    "                    for _ in range(1, len(states_to_train)):\n",
    "                        targets.append(targets[-1] - 0.1)\n",
    "                    targets.reverse()\n",
    "                    network.fit(np.array(states_to_train), np.array(targets), epochs=1, batch_size=len(targets), validation_split=0.0)\n",
    "                    \n",
    "                done = True\n",
    "                solved.append(iteration_number != iteration_number_max)\n",
    "                print(\"solved:\", iteration_number != iteration_number_max)\n",
    "                \n",
    "    return np.array(solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_starting_positions(env, number):\n",
    "    snapshots = []\n",
    "    for _ in range(number):\n",
    "        env.reset()\n",
    "        snapshots.append(env.get_state_snapshot())\n",
    "    return snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d2e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SokobanEnv((6, 6), 50, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75008d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_positions = generate_starting_positions(env, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968774f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearn_network = ClassificationNetwork(env.observation_space.shape, learning_rate = 1e-2)\n",
    "prelearn_network.load_weights('classification_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e4b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearned_no_train_class_20 = run_experiment(env, prelearn_network, net_type='classification', rollouts=20, init_states=starting_positions, train=False, iteration_number_max=50)\n",
    "prelearned_no_train_class_20.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ddf7a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prelearned_no_train_class_40 = run_experiment(env, prelearn_network, net_type='classification', rollouts=40, init_states=starting_positions, train=False, iteration_number_max=50)\n",
    "prelearned_no_train_class_40.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ca578c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prelearned_no_train_class_60 = run_experiment(env, prelearn_network, net_type='classification', rollouts=60, init_states=starting_positions, train=False, iteration_number_max=50)\n",
    "prelearned_no_train_class_60.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearn_network = ValueNetwork(env.observation_space.shape, learning_rate = 1e-2)\n",
    "prelearn_network.load_weights('value_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199d1bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prelearned_no_train_value_20 = run_experiment(env, prelearn_network, net_type='value', rollouts=20, init_states=starting_positions, train=False, iteration_number_max=50)\n",
    "prelearned_no_train_value_20.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearned_no_train_value_40 = run_experiment(env, prelearn_network, net_type='value', rollouts=40, init_states=starting_positions, train=False, iteration_number_max=50)\n",
    "prelearned_no_train_value_40.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d862a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prelearned_no_train_value_60 = run_experiment(env, prelearn_network, net_type='value', rollouts=60, init_states=starting_positions, train=False, iteration_number_max=50)\n",
    "prelearned_no_train_value_60.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here the values are hardcoded as they were overwriten by another run of experiments\n",
    "plt.plot([20, 40, 60], [0.42, 0.38, 0.4], label='With simple fields')\n",
    "\n",
    "plt.plot([20, 40, 60], [prelearned_no_train_value_20, prelearned_no_train_value_40, prelearned_no_train_value_60], label='No simple fields')\n",
    "plt.legend()\n",
    "plt.xlabel('Rollouts')\n",
    "plt.ylabel('Solved rate')\n",
    "plt.title('6x6 fields, two boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08041bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearn_network = ValueNetwork(env.observation_space.shape, learning_rate = 1e-2)\n",
    "prelearn_network.load_weights('value_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c94916",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearned_train_value_20 = run_experiment(env, prelearn_network, net_type='value', rollouts=20, init_states=starting_positions, train=True, iteration_number_max=50)\n",
    "prelearned_train_value_20.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5903d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearn_network = ValueNetwork(env.observation_space.shape, learning_rate = 1e-2)\n",
    "prelearn_network.load_weights('value_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearned_train_value_40 = run_experiment(env, prelearn_network, net_type='value', rollouts=40, init_states=starting_positions, train=True, iteration_number_max=50)\n",
    "prelearned_train_value_40.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearn_network = ValueNetwork(env.observation_space.shape, learning_rate = 1e-2)\n",
    "prelearn_network.load_weights('value_network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearned_train_value_60 = run_experiment(env, prelearn_network, net_type='value', rollouts=60, init_states=starting_positions, train=True, iteration_number_max=50)\n",
    "prelearned_train_value_60.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12870615",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([20, 40, 60], [prelearned_no_train_value_20, prelearned_no_train_value_40, prelearned_no_train_value_60], label='Value Network with training')\n",
    "plt.plot([20, 40, 60], [prelearned_train_value_20, prelearned_train_value_40, prelearned_train_value_60], label='Value Network without training')\n",
    "plt.legend()\n",
    "plt.xlabel('Rollouts')\n",
    "plt.ylabel('Solved rate')\n",
    "plt.title('6x6 fields, two boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35595bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
